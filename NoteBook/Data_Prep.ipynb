{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7uvLXeMZ_Wb"
      },
      "source": [
        "# Unzip File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMb9LhIu7Ay7",
        "outputId": "99ec7598-0383-49d6-844f-0687d12331a4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSBPGfWZqDKG",
        "outputId": "562ddde6-9285-4c0f-de12-f256bd6829c1"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/My Drive/OMSCS/OMSCS_DL_Project/GenImage/BigGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40cadI86qNou",
        "outputId": "0508d8e4-9728-4596-f6e9-b71c57c224d8"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgNvZLEnZ33W",
        "outputId": "ca892ad3-34f6-4312-ec3b-b8f4d0dda5c6"
      },
      "outputs": [],
      "source": [
        "! pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wevYIC50G1j",
        "outputId": "0dcb592c-af3c-4ed5-b78f-7c186047b5f3"
      },
      "outputs": [],
      "source": [
        "! ls /content/sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtSHPwnzqPNs",
        "outputId": "18c52198-10c2-4cca-8d34-87e312fe6535"
      },
      "outputs": [],
      "source": [
        "! unzip unsplit.zip -d /content/sample_data/BigGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5er1YKCBrc9y"
      },
      "outputs": [],
      "source": [
        "# %cp -r /content/sample_data/BigGAN/ /content/drive/MyDrive/OMSCS_DL_Project/GenImage/BigGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbMMAIrErtJB"
      },
      "outputs": [],
      "source": [
        "# ! zip -F imagenet_ai_0508_adm.zip --out unsplit.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLXsVhCSaImZ"
      },
      "source": [
        "## Check Number of files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O95pqc8-bNXM",
        "outputId": "e2a4e9cf-d536-4150-e3e7-1988dd1e6442"
      },
      "outputs": [],
      "source": [
        "! ls /content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/ai | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6rVaYYTcUb0",
        "outputId": "d950b97a-99f9-4066-8f4c-312f9c92e5c0"
      },
      "outputs": [],
      "source": [
        "! ls /content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/nature/ | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwZXZee3cigE",
        "outputId": "4cee6191-f87a-4582-c8f9-81e460bd5aac"
      },
      "outputs": [],
      "source": [
        "! ls /content/sample_data/BigGAN/imagenet_ai_0419_biggan/val/ai | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_v3uZ2actGw",
        "outputId": "a64ee243-4839-4412-cd41-42cfcfb12a6e"
      },
      "outputs": [],
      "source": [
        "! ls /content/sample_data/BigGAN/imagenet_ai_0419_biggan/val/nature/ | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecZcRwPIaUZM"
      },
      "source": [
        "Show Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "g7oXOxi1aTzR",
        "outputId": "a2aa1fdd-67cc-4910-9553-f6ae639eeb5d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure()\n",
        "img = mpimg.imread('/content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/nature/n01582220_4551.JPEG')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJrkRVKKaMO2"
      },
      "source": [
        "# Prepare Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2BTr3haAvis"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import torch\n",
        "\n",
        "from skimage import io, transform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClNOPgqxgEid"
      },
      "outputs": [],
      "source": [
        "dataset_type = 'val'\n",
        "model_type = 'nature'\n",
        "root_dir = '/content/sample_data/BigGAN/imagenet_ai_0419_biggan'\n",
        "\n",
        "image_name = os.listdir(os.path.join(root_dir, dataset_type, model_type))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "MObCxRVikn1c",
        "outputId": "c4b41b90-657a-4a4b-a2d0-35c3ba950033"
      },
      "outputs": [],
      "source": [
        "image_name = os.path.join(root_dir, dataset_type, model_type,image_name[100])\n",
        "plt.figure()\n",
        "img = mpimg.imread(image_name)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3WbooSGNVi4"
      },
      "outputs": [],
      "source": [
        "# example: plots do not have three layers\n",
        "# from IPython.display import Image\n",
        "# Image(filename='/content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/nature/n02092002_1032.JPEG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqHeHrUm-QpH",
        "outputId": "d1e5c3f4-ddef-4b4a-ab82-6e353f930e78"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/My Drive/OMSCS/OMSCS_DL_Project/Deep_Learning_Final_Project/Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZFIQI_xVT3n",
        "outputId": "31ece8c7-9eb2-4e70-d20f-8e4ca6fea038"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAm0pck3RgZo"
      },
      "outputs": [],
      "source": [
        "from data_prep_util import GenImageDataset, Rescale, HighPassFilter, State, CheckPoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters and configurations\n",
        "class Config:\n",
        "    # for data loader\n",
        "    batch_size = 32\n",
        "    num_workers = 8\n",
        "\n",
        "    # number of epochs during training\n",
        "    num_epochs = 4\n",
        "\n",
        "    # learning rate for learnable parameters\n",
        "    learning_rate = 3e-5\n",
        "\n",
        "    # Define an MLP with 2 or 3 layers\n",
        "    hidden_dim1 = 500\n",
        "    hidden_dim2 = 500\n",
        "\n",
        "    # dropout in head\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Set to False to disable the high pass filter\n",
        "    use_filter = False\n",
        "\n",
        "    # Adjust alpha between 0 and 1 for the desired effect for the high pass filter\n",
        "    alpha_value = 0.5\n",
        "\n",
        "    # Set to True if you want to use pretrained weights\n",
        "    pretrained = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_transformations(use_high_pass_filter=False, alpha_value=0.5, rescale_size = 256):\n",
        "    transformations = [Rescale(rescale_size)]\n",
        "    if use_high_pass_filter:\n",
        "        transformations.append(HighPassFilter(alpha=alpha_value))\n",
        "    return transforms.Compose(transformations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUkzR-5pnYIO"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_type = 'train'\n",
        "# model_type = 'nature'\n",
        "root_dir = '/content/sample_data/BigGAN/imagenet_ai_0419_biggan'\n",
        "\n",
        "BigGen_train_nature = GenImageDataset(root_dir, dataset_type, 'nature',\n",
        "                                      transform=get_transformations(Config.use_filter, Config.alpha_value))\n",
        "\n",
        "BigGen_train_ai = GenImageDataset(root_dir, dataset_type, 'ai',\n",
        "                                  transform=get_transformations(Config.use_filter, Config.alpha_value))\n",
        "\n",
        "BigGen_train = torch.utils.data.ConcatDataset([BigGen_train_nature, BigGen_train_ai])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vofDdgnK1Rs"
      },
      "outputs": [],
      "source": [
        "dataset_type = 'val'\n",
        "\n",
        "BigGen_val_nature = GenImageDataset(root_dir, dataset_type, 'nature',\n",
        "                                    transform=get_transformations(Config.use_filter, Config.alpha_value))\n",
        "\n",
        "BigGen_val_ai = GenImageDataset(root_dir, dataset_type, 'ai',\n",
        "                                transform=get_transformations(Config.use_filter, Config.alpha_value))\n",
        "\n",
        "BigGen_val = torch.utils.data.ConcatDataset([BigGen_val_nature, BigGen_val_ai])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUpiGVXsLCsd",
        "outputId": "8d4980ff-20e2-459c-b705-22930bc77166"
      },
      "outputs": [],
      "source": [
        "len(BigGen_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcSOSP2vAK0r",
        "outputId": "28f52f96-24ac-471a-a796-68ca8ad93429"
      },
      "outputs": [],
      "source": [
        "len(BigGen_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ7aCLJ6M6lK",
        "outputId": "baf27ce6-25d9-477f-b947-1af96c37acb6"
      },
      "outputs": [],
      "source": [
        "BigGen_train[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-vZ1-_0n9zA",
        "outputId": "8ff1c8b2-c8de-4769-f3b1-9e1f0696e1f4"
      },
      "outputs": [],
      "source": [
        "BigGen_train[100]['image'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "zFkATzPQnkL7",
        "outputId": "b9543e2b-f0cc-43dc-ac80-b28b06dc2988"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "img = BigGen_train[100]['image']\n",
        "imgplot = plt.imshow(img.permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEPrXJzT78z5"
      },
      "outputs": [],
      "source": [
        "next(iter(BigGen_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNlxeNGh1aI9"
      },
      "source": [
        "# Create Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00PhgSMT05bQ"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# train_dataloader = DataLoader(BigGen_train, batch_size=64, shuffle=True)\n",
        "# val_dataloader = DataLoader(BigGen_val, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvbSxHNbF4TH"
      },
      "source": [
        "https://discuss.pytorch.org/t/dataloader-resets-dataset-state/27960\n",
        "\n",
        "https://discuss.pytorch.org/t/pytorch-dataloaders-in-memory/118471"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGZwGk5FAVVA"
      },
      "source": [
        "# Try Swin Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA7aihvgBbtD"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX-Vydb5AUlu",
        "outputId": "5728a995-c14d-43ae-f19d-5aa8dd52fb82"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load the pre-trained Swin Transformer model\n",
        "# model = models.swin_t(weights=models.Swin_T_Weights.IMAGENET1K_V1, progress=True)\n",
        "\n",
        "# Initialize the Swin Transformer model without pretrained weights\n",
        "model = models.swin_t(pretrained=Config.pretrained)  # Notice pretrained is set to False\n",
        "\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "'''\n",
        "For transfer learning, uncomment to freeze the pretrained weights\n",
        "'''\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "classes = ['ai','nature']\n",
        "\n",
        "mlp_head = nn.Sequential(\n",
        "    nn.Linear(model.head.in_features, Config.hidden_dim1),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(Config.dropout),\n",
        "    nn.Linear(Config.hidden_dim1, Config.hidden_dim2),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(Config.dropout),\n",
        "    nn.Linear(Config.hidden_dim2, len(classes))\n",
        ").to(device)\n",
        "\n",
        "# Update the classifier head to the new MLP\n",
        "model.head = mlp_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2XpTEAHA5s3"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(predictions, labels):\n",
        "    _, preds = torch.max(predictions, 1)\n",
        "    return (preds == labels).float().mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvSNiSRCBqlY"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(BigGen_train, batch_size=Config.batch_size, shuffle=False)\n",
        "testloader = DataLoader(BigGen_val, batch_size=Config.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDRxlY9qBUu1",
        "outputId": "85c25427-8f16-4463-9c6e-2d35d04ea29a"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "import time  # Import the time module\n",
        "\n",
        "scaler = GradScaler()  # Initialize the GradScaler\n",
        "\n",
        "train_loss_history, val_loss_history, train_acc_history, val_acc_history = [], [], [], []\n",
        "total_training_start = time.time()  # Record the start time of the total training\n",
        "starting_epoch = 0\n",
        "load_latest_model = True\n",
        "\n",
        "state = CheckPoint.load_checkpoint()\n",
        "if state is not None and load_latest_model:\n",
        "    print('LOADING FROM CHECKPOINT')\n",
        "    model.load_state_dict(state.model_state_dict)\n",
        "    starting_epoch = state.epoch + 1\n",
        "    trainloader = state.trainloader\n",
        "    testloader = state.testloader\n",
        "    train_loss_history = state.train_loss_history\n",
        "    train_acc_history = state.train_acc_history\n",
        "    val_loss_history = state.val_loss_history\n",
        "    val_acc_history = state.val_acc_history\n",
        "    criterion.load_state_dict(state.criterion_state_dict)\n",
        "    optimizer.load_state_dict(state.optimizer_state_dict)\n",
        "    scaler.load_state_dict(state.scaler_state_dict)\n",
        "    print('starting_epoch', starting_epoch)\n",
        "    print('train_loss_history', train_loss_history)\n",
        "    print('train_acc_history', train_acc_history)\n",
        "    print('val_loss_history', val_loss_history)\n",
        "    print('val_acc_history', val_acc_history)\n",
        "\n",
        "for epoch in range(starting_epoch, Config.num_epochs):\n",
        "    epoch_start = time.time()  # Record the start time of the epoch\n",
        "\n",
        "    train_loss, train_acc, val_loss, val_acc = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "    # Training Phase\n",
        "    model.train()\n",
        "    pbar = tqdm(enumerate(trainloader), total=len(trainloader),\n",
        "                desc=f\"Epoch {epoch+1} TRAIN\", ncols=100)\n",
        "    for i, data in pbar:\n",
        "        inputs = data['image']\n",
        "        inputs = inputs.to(torch.float)\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        labels = data['model_type']\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        dataset = data['dataset_type']\n",
        "        image_name = data['image_name']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_acc += accuracy(outputs, labels)\n",
        "\n",
        "        pbar.set_description(f\"Epoch {epoch+1} TRAIN Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    pbar = tqdm(enumerate(testloader), total=len(testloader),\n",
        "                desc=f\"Epoch {epoch+1} VAL\", ncols=100)\n",
        "    with torch.no_grad():\n",
        "        for i, data in pbar:\n",
        "            inputs = data['image']\n",
        "            inputs = inputs.to(torch.float)\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            labels = data['model_type']\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            dataset = data['dataset_type']\n",
        "            image_name = data['image_name']\n",
        "\n",
        "            # inputs, labels, dataset = inputs.cuda(), labels.cuda(), dataset.cuda()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += accuracy(outputs, labels)\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"Epoch {epoch+1} VAL Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_end = time.time()  # Record the end time of the epoch\n",
        "    # Calculate the duration in minutes\n",
        "    epoch_duration = (epoch_end - epoch_start) / 60\n",
        "\n",
        "    train_loss /= len(trainloader)\n",
        "    train_acc /= len(trainloader)\n",
        "    val_loss /= len(testloader)\n",
        "    val_acc /= len(testloader)\n",
        "\n",
        "    train_loss_history.append(train_loss)\n",
        "    train_acc_history.append(train_acc)\n",
        "    val_loss_history.append(val_loss)\n",
        "    val_acc_history.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch Summary {epoch+1}/{Config.num_epochs}\")\n",
        "    print(\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
        "    print(f\"Epoch Duration: {epoch_duration:.2f} minutes\")\n",
        "    print('-' * 60)\n",
        "\n",
        "    state = State(\n",
        "        model_state_dict = model.state_dict(),\n",
        "        epoch = epoch,\n",
        "        trainloader = trainloader,\n",
        "        testloader = testloader,\n",
        "        train_loss_history = train_loss_history,\n",
        "        train_acc_history = train_acc_history,\n",
        "        val_loss_history = val_loss_history,\n",
        "        val_acc_history = val_acc_history,\n",
        "        criterion_state_dict = criterion.state_dict(),\n",
        "        optimizer_state_dict = optimizer.state_dict(),\n",
        "        scaler_state_dict = scaler.state_dict(),\n",
        "    )\n",
        "    CheckPoint.save_checkpoint(state)\n",
        "\n",
        "total_training_end = time.time()  # Record the end time of the total training\n",
        "# Calculate the total duration in minutes\n",
        "total_training_duration = (total_training_end - total_training_start) / 60\n",
        "print('Finished Training')\n",
        "print(f\"Total Training Time: {total_training_duration:.2f} minutes\")\n",
        "\n",
        "# https://stackoverflow.com/questions/59129812/how-to-avoid-cuda-out-of-memory-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2dJuzwRn17T"
      },
      "outputs": [],
      "source": [
        "# from itertools import islice\n",
        "\n",
        "# for i,data in enumerate(trainloader):\n",
        "#   if i>5200:\n",
        "#     print(data['image'].shape)\n",
        "#     print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9ckNL2Hx0wkR",
        "outputId": "f5304f0a-900e-47a0-f299-8258e635ce5f"
      },
      "outputs": [],
      "source": [
        "# plots with errors\n",
        "# /content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/ai/116_biggan_00098.png\n",
        "# /content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/ai/116_biggan_00107.png\n",
        "plt.figure()\n",
        "img = mpimg.imread('/content/sample_data/BigGAN/imagenet_ai_0419_biggan/train/ai/116_biggan_00094.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "o0LIc4GvN--i",
        "outputId": "ab9d5e68-cc4d-4954-ae57-8865a58447a7"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model, inputs, labels, dataset, image_name\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7g2nN5iHwhq"
      },
      "outputs": [],
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
